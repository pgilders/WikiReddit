{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import syft as sy\n",
    "import time\n",
    "import os\n",
    "import dotenv\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged into <reddit-for-researchers-internal: High side Datasite> as <prgildersleve@gmail.com>\n"
     ]
    }
   ],
   "source": [
    "# we recommend that you source these values using environment variables\n",
    "dotenv.load_dotenv()\n",
    "URL = \"https://reddit-for-researchers.snooguts.net\"\n",
    "EMAIL = os.getenv(\"EMAIL\")\n",
    "PASSWORD = os.getenv(\"PASSWORD\")\n",
    "\n",
    "# you can provide a \"password\" keyword argument, but if you don't...\n",
    "# the browser will prompt you for input\n",
    "client = sy.login(\n",
    "    url=URL,\n",
    "    email=EMAIL,\n",
    "    password=PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_id_dict(client):\n",
    "    # TODO handle case with duplicate names?\n",
    "    return {request.code.service_func_name: str(request.id) for request in client.requests}\n",
    "\n",
    "\n",
    "def query_r4r(function_name, name_to_id_dict, client):\n",
    "\n",
    "    while True:   \n",
    "        try:\n",
    "            request = client.api.services.request.get_by_uid(uid=sy.UID(name_to_id_dict[function_name]))\n",
    "            job = request.code(blocking=False)\n",
    "            results = job.wait()\n",
    "            df = results.get()\n",
    "            return df\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            time.sleep(10)\n",
    "            client = sy.login(\n",
    "                url=URL,\n",
    "                email=EMAIL,\n",
    "                password=PASSWORD\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcdict = name_to_id_dict(client)\n",
    "funcdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = client.api.services.request.get_by_uid(uid=sy.UID(funcdict[\"avg_comment_score_pg\"]))\n",
    "job = request.code(blocking=False)\n",
    "results = job.wait()\n",
    "results.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posts\n",
    "\n",
    "posts_dict = {}\n",
    "for year in range(2020, 2024):\n",
    "    key = f\"pg_wiki_{year}\"\n",
    "    print(key)\n",
    "    try:\n",
    "        posts_dict[key] = pd.read_hdf(f\"data/{key}.h5\")\n",
    "    except:\n",
    "        posts_dict[key] = query_r4r(key, funcdict, client)\n",
    "        for c in ['score', 'gildings', 'num_comments']:\n",
    "            posts_dict[key][c] = posts_dict[key][c].astype(np.int64)\n",
    "        for c in ['nsfw', 'self', 'video', 'locked', 'spoiler', 'sticky']:\n",
    "            posts_dict[key][c] = posts_dict[key][c].astype(np.bool_)\n",
    "        for c in ['created_at', 'updated_at']:\n",
    "            posts_dict[key][c] = pd.to_datetime(posts_dict[key][c]).astype('datetime64[ns]')\n",
    "\n",
    "        posts_dict[key].to_hdf(f\"data/{key}.h5\", key='df', mode='w')\n",
    "\n",
    "posts_df = pd.concat(posts_dict.values())\n",
    "posts_df.to_hdf(\"data/posts.h5\", key='df', mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = pd.read_hdf(\"data/posts.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "\n",
    "comments_dict = {}\n",
    "for year in range(2020, 2024):\n",
    "    for month in range(1, 13):\n",
    "        key = f\"pg_wiki_comments_{year}{month:02d}\"\n",
    "        print(key)\n",
    "        try:\n",
    "            comments_dict[key] = pd.read_hdf(f\"data/{key}.h5\")\n",
    "        except:\n",
    "            comments_dict[key] = query_r4r(key, funcdict, client)\n",
    "            for c in ['score']:\n",
    "                comments_dict[key][c] = comments_dict[key][c].astype(np.int64)\n",
    "            for c in ['gilded']:\n",
    "                comments_dict[key][c] = comments_dict[key][c].astype(np.bool_)\n",
    "            for c in ['created_at', 'last_modified_at']:\n",
    "                comments_dict[key][c] = pd.to_datetime(comments_dict[key][c]).astype('datetime64[ns]')\n",
    "            comments_dict[key].to_hdf(f\"data/{key}.h5\", key='df', mode='w')\n",
    "\n",
    "comments_df = pd.concat(comments_dict.values())\n",
    "os.remove(\"data/comments_1.h5\")\n",
    "comments_df.iloc[:len(comments_df)//4].to_hdf(\"data/comments_1.h5\", key='df', mode='w')\n",
    "os.remove(\"data/comments_2.h5\")\n",
    "comments_df.iloc[len(comments_df)//4:len(comments_df)//2].to_hdf(\"data/comments_2.h5\", key='df', mode='w')\n",
    "os.remove(\"data/comments_3.h5\")\n",
    "comments_df.iloc[len(comments_df)//2:len(comments_df)//4*3].to_hdf(\"data/comments_3.h5\", key='df', mode='w')\n",
    "os.remove(\"data/comments_4.h5\")\n",
    "comments_df.iloc[len(comments_df)//4*3:].to_hdf(\"data/comments_4.h5\", key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  replies\n",
    "\n",
    "replies_df = query_r4r('pg_wiki_replies', funcdict, client)\n",
    "for c in ['score']:\n",
    "    replies_df[c] = replies_df[c].astype(np.int64)\n",
    "for c in ['gilded']:\n",
    "    replies_df[c] = replies_df[c].astype(np.bool_)\n",
    "for c in ['created_at', 'last_modified_at']:\n",
    "    replies_df[c] = pd.to_datetime(replies_df[c]).astype('datetime64[ns]')\n",
    "replies_df.to_hdf(f\"data/replies.h5\", key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replies\n",
    "\n",
    "replies_dict = {}\n",
    "for year in range(2020, 2024):\n",
    "    key = f\"pg_wiki_replies_{year}\"\n",
    "    print(key)\n",
    "    try:\n",
    "        replies_dict[key] = pd.read_hdf(f\"data/{key}.h5\")\n",
    "    except:\n",
    "        replies_dict[key] = query_r4r(key, funcdict, client)\n",
    "        for c in ['score']:\n",
    "            replies_dict[key][c] = replies_dict[key][c].astype(np.int64)\n",
    "        for c in ['gilded']:\n",
    "            replies_dict[key][c] = replies_dict[key][c].astype(np.bool_)\n",
    "        for c in ['created_at', 'last_modified_at']:\n",
    "            replies_dict[key][c] = pd.to_datetime(replies_dict[key][c]).astype('datetime64[ns]')\n",
    "\n",
    "        replies_dict[key].to_hdf(f\"data/{key}.h5\", key='df', mode='w')\n",
    "\n",
    "replies_df = pd.concat(replies_dict.values())\n",
    "os.remove(\"data/replies.h5\")\n",
    "replies_df.to_hdf(\"data/replies.h5\", key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replies_dict = {}\n",
    "for year in range(2020, 2024):\n",
    "    for month in range(1, 13):\n",
    "        key = f\"pg_wiki_replies_{year}\"\n",
    "        print(key)\n",
    "        try:\n",
    "            replies_dict[key] = pd.read_hdf(f\"data/{key}.h5\")\n",
    "        except:\n",
    "            replies_dict[key] = query_r4r(key, funcdict, client)\n",
    "            for c in ['score']:\n",
    "                replies_dict[key][c] = replies_dict[key][c].astype(np.int64)\n",
    "            for c in ['gilded']:\n",
    "                replies_dict[key][c] = replies_dict[key][c].astype(np.bool_)\n",
    "            for c in ['created_at', 'last_modified_at']:\n",
    "                replies_dict[key][c] = pd.to_datetime(replies_dict[key][c]).astype('datetime64[ns]')\n",
    "\n",
    "            replies_dict[key].to_hdf(f\"data/{key}.h5\", key='df', mode='w')\n",
    "\n",
    "replies_df = pd.concat(replies_dict.values())\n",
    "os.remove(\"data/replies.h5\")\n",
    "replies_df.to_hdf(\"data/replies.h5\", key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = pd.read_hdf(\"data/posts.h5\")\n",
    "comments_df = pd.concat([pd.read_hdf(f\"data/comments_{i}.h5\") for i in range(1, 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_132352/3707721486.py:4: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index(['id', 'subreddit_id', 'title', 'body', 'url', 'author_id',\n",
      "       'distinguished', 'flair_text', 'language_code', 'thumbnail',\n",
      "       'crosspost_parent_id', 'permalink'],\n",
      "      dtype='object')]\n",
      "\n",
      "  posts_df.to_hdf(\"data/posts.h5\", key='df', mode='w')\n",
      "/tmp/ipykernel_132352/3707721486.py:7: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block4_values] [items->Index(['id', 'post_id', 'parent_id', 'body', 'author_id', 'subreddit_id',\n",
      "       'permalink'],\n",
      "      dtype='object')]\n",
      "\n",
      "  comments_df.iloc[len(comments_df)//4*(i-1):len(comments_df)//4*i].to_hdf(f\"data/comments_{i}.h5\", key='df', mode='w')\n",
      "/tmp/ipykernel_132352/3707721486.py:7: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block4_values] [items->Index(['id', 'post_id', 'parent_id', 'body', 'author_id', 'subreddit_id',\n",
      "       'permalink'],\n",
      "      dtype='object')]\n",
      "\n",
      "  comments_df.iloc[len(comments_df)//4*(i-1):len(comments_df)//4*i].to_hdf(f\"data/comments_{i}.h5\", key='df', mode='w')\n",
      "/tmp/ipykernel_132352/3707721486.py:7: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block4_values] [items->Index(['id', 'post_id', 'parent_id', 'body', 'author_id', 'subreddit_id',\n",
      "       'permalink'],\n",
      "      dtype='object')]\n",
      "\n",
      "  comments_df.iloc[len(comments_df)//4*(i-1):len(comments_df)//4*i].to_hdf(f\"data/comments_{i}.h5\", key='df', mode='w')\n",
      "/tmp/ipykernel_132352/3707721486.py:7: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block4_values] [items->Index(['id', 'post_id', 'parent_id', 'body', 'author_id', 'subreddit_id',\n",
      "       'permalink'],\n",
      "      dtype='object')]\n",
      "\n",
      "  comments_df.iloc[len(comments_df)//4*(i-1):len(comments_df)//4*i].to_hdf(f\"data/comments_{i}.h5\", key='df', mode='w')\n"
     ]
    }
   ],
   "source": [
    "posts_df.loc[posts_df['updated_at'] == pd.Timestamp('1970-01-01 00:00:00'), 'updated_at'] = pd.NaT\n",
    "comments_df.loc[comments_df['last_modified_at'] == pd.Timestamp('1970-01-01 00:00:00'), 'last_modified_at'] = pd.NaT\n",
    "\n",
    "posts_df.to_hdf(\"data/posts.h5\", key='df', mode='w')\n",
    "for i in range(1, 5):\n",
    "    os.remove(f\"data/comments_{i}.h5\")\n",
    "    comments_df.iloc[len(comments_df)//4*(i-1):len(comments_df)//4*i].to_hdf(f\"data/comments_{i}.h5\", key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: updated_at, dtype: datetime64[ns])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: last_modified_at, dtype: datetime64[ns])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(posts_df['updated_at'][(posts_df['updated_at'] == pd.Timestamp('1970-01-01 00:00:00'))])\n",
    "display(comments_df['last_modified_at'][(comments_df['last_modified_at'] == pd.Timestamp('1970-01-01 00:00:00'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df.loc[posts_df['updated_at'] == pd.Timestamp('1970-01-01 00:00:00'), 'updated_at'] = pd.NaT\n",
    "comments_df.loc[comments_df['last_modified_at'] == pd.Timestamp('1970-01-01 00:00:00'), 'last_modified_at'] = pd.NaT\n",
    "ccols = ['subreddit_id', 'post_id', 'parent_id', 'id', 'created_at',\n",
    "         'last_modified_at', 'score', 'upvote_ratio', 'gilded']\n",
    "cw = comments_df[ccols]\n",
    "pcols = ['subreddit_id', 'crosspost_parent_id', 'id', 'created_at', 'updated_at',\n",
    "         'language_code', 'score', 'upvote_ratio', 'gildings', 'num_comments']\n",
    "pw = posts_df[pcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10264340"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  create sqlite database\n",
    "conn = sqlite3.connect('wikireddit.db')\n",
    "posts_df[pcols].to_sql('posts', conn, index=False, if_exists='replace')\n",
    "comments_df[ccols].to_sql('comments', conn, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>crosspost_parent_id</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>language_code</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>gildings</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t5_30dxu</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_iju85e</td>\n",
       "      <td>2020-08-31 08:23:57.595000</td>\n",
       "      <td>2020-08-31 08:27:18.247449</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t5_2qh16</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_evva62</td>\n",
       "      <td>2020-01-29 23:16:54.860000</td>\n",
       "      <td>2020-01-29 23:38:45.353244</td>\n",
       "      <td>en</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t5_2qh4r</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_ini49k</td>\n",
       "      <td>2020-09-06 07:48:47.668000</td>\n",
       "      <td>2020-09-06 13:53:40.374281</td>\n",
       "      <td>en</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t5_2qhhq</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_g7m4zn</td>\n",
       "      <td>2020-04-25 02:51:48.375000</td>\n",
       "      <td>2020-05-10 12:06:23.576164</td>\n",
       "      <td>en</td>\n",
       "      <td>252</td>\n",
       "      <td>0.872781</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t5_2qiu7</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_htkzqv</td>\n",
       "      <td>2020-07-18 18:00:51.386000</td>\n",
       "      <td>2020-11-16 19:25:23.710963</td>\n",
       "      <td>en</td>\n",
       "      <td>22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit_id crosspost_parent_id         id                  created_at  \\\n",
       "0     t5_30dxu                None  t3_iju85e  2020-08-31 08:23:57.595000   \n",
       "1     t5_2qh16                None  t3_evva62  2020-01-29 23:16:54.860000   \n",
       "2     t5_2qh4r                None  t3_ini49k  2020-09-06 07:48:47.668000   \n",
       "3     t5_2qhhq                None  t3_g7m4zn  2020-04-25 02:51:48.375000   \n",
       "4     t5_2qiu7                None  t3_htkzqv  2020-07-18 18:00:51.386000   \n",
       "\n",
       "                   updated_at language_code  score  upvote_ratio  gildings  \\\n",
       "0  2020-08-31 08:27:18.247449            en      2      1.000000         0   \n",
       "1  2020-01-29 23:38:45.353244            en     -1      0.333333         0   \n",
       "2  2020-09-06 13:53:40.374281            en     -1      0.333333         0   \n",
       "3  2020-05-10 12:06:23.576164            en    252      0.872781         0   \n",
       "4  2020-11-16 19:25:23.710963            en     22      1.000000         0   \n",
       "\n",
       "   num_comments  \n",
       "0             6  \n",
       "1             3  \n",
       "2             2  \n",
       "3           103  \n",
       "4             1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified_at</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>gilded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t5_2r0z5</td>\n",
       "      <td>t3_etay7w</td>\n",
       "      <td>t1_fff9hw3</td>\n",
       "      <td>t1_fffb0wn</td>\n",
       "      <td>2020-01-24 15:33:19.870000</td>\n",
       "      <td>2020-01-26 13:20:38.671925</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t5_m0bnr</td>\n",
       "      <td>t3_esaarr</td>\n",
       "      <td>t1_ff9cuei</td>\n",
       "      <td>t1_ff9g8pq</td>\n",
       "      <td>2020-01-22 16:59:19.075000</td>\n",
       "      <td>2020-01-23 05:45:03.148202</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t5_2sw51</td>\n",
       "      <td>t3_evtkjd</td>\n",
       "      <td>t1_ffxzb0u</td>\n",
       "      <td>t1_ffy2irk</td>\n",
       "      <td>2020-01-29 22:35:26.247000</td>\n",
       "      <td>2020-01-30 18:39:07.158948</td>\n",
       "      <td>69</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t5_2qkhk</td>\n",
       "      <td>t3_ejacx2</td>\n",
       "      <td>t1_fcwy5m3</td>\n",
       "      <td>t1_fcx0nes</td>\n",
       "      <td>2020-01-03 10:05:22.663000</td>\n",
       "      <td>2020-01-04 17:11:59.126507</td>\n",
       "      <td>31</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t5_2ti4h</td>\n",
       "      <td>t3_eijy3m</td>\n",
       "      <td>t1_fcruhz4</td>\n",
       "      <td>t1_fcs6j6m</td>\n",
       "      <td>2020-01-01 20:55:31.722000</td>\n",
       "      <td>2020-05-01 00:59:11.366739</td>\n",
       "      <td>88</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit_id    post_id   parent_id          id                  created_at  \\\n",
       "0     t5_2r0z5  t3_etay7w  t1_fff9hw3  t1_fffb0wn  2020-01-24 15:33:19.870000   \n",
       "1     t5_m0bnr  t3_esaarr  t1_ff9cuei  t1_ff9g8pq  2020-01-22 16:59:19.075000   \n",
       "2     t5_2sw51  t3_evtkjd  t1_ffxzb0u  t1_ffy2irk  2020-01-29 22:35:26.247000   \n",
       "3     t5_2qkhk  t3_ejacx2  t1_fcwy5m3  t1_fcx0nes  2020-01-03 10:05:22.663000   \n",
       "4     t5_2ti4h  t3_eijy3m  t1_fcruhz4  t1_fcs6j6m  2020-01-01 20:55:31.722000   \n",
       "\n",
       "             last_modified_at  score  upvote_ratio  gilded  \n",
       "0  2020-01-26 13:20:38.671925     -3      0.363636       0  \n",
       "1  2020-01-23 05:45:03.148202     50      1.000000       0  \n",
       "2  2020-01-30 18:39:07.158948     69      1.000000       0  \n",
       "3  2020-01-04 17:11:59.126507     31      0.969697       0  \n",
       "4  2020-05-01 00:59:11.366739     88      0.988889       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test read some rows from each table\n",
    "conn = sqlite3.connect('wikireddit.db')\n",
    "display(pd.read_sql('SELECT * FROM posts LIMIT 5', conn))\n",
    "display(pd.read_sql('SELECT * FROM comments LIMIT 5', conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database size: 1191.16 MB\n"
     ]
    }
   ],
   "source": [
    "# get storage size of database\n",
    "import os\n",
    "mb_size = os.path.getsize('wikireddit.db') / 1024 / 1024\n",
    "print(f\"Database size: {mb_size:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
